{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simulation using Python, Lab 2, Part B"
      ],
      "metadata": {
        "id": "jCYxZA0Ksgwt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mEq66v4PziL"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploration**\n",
        "Randomly explore the search space and report the best solution found for the Rosenbrock Function"
      ],
      "metadata": {
        "id": "GrYHWMdgstZG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuQDD_oiQDC0"
      },
      "source": [
        "#Let's define the 2-D Rosenbrock function\n",
        "def Rosenbrock(x1, x2):\n",
        "  return ((1-x1)**2 + 100*(x2 -x1**2)**2)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS6qfA6jQLQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94b591e6-66e3-4b5a-fea8-d3997f812c90"
      },
      "source": [
        "N = 10000 ## number of random points\n",
        "D = 2 ##Dimension \n",
        "lb = -4 ## lower bound\n",
        "ub = 4  ## upper bound\n",
        "\n",
        "X1=[]\n",
        "X2=[]\n",
        "Y=[]\n",
        "\n",
        "#randomly generate N points. We are using Numpy's random package here.\n",
        "X1 = np.random.uniform(lb, ub, N)\n",
        "X2 = np.random.uniform(lb, ub, N)\n",
        "\n",
        "#Evaluate the function\n",
        "for i in range(N):\n",
        "    Y.append(Rosenbrock(X1[i], X2[i]))\n",
        "    \n",
        "#display Results\n",
        "print('\\n Monte Carlo Simulation Optimisation\\n')\n",
        "print( 'Best decision variable : ', X1[np.argmin(Y)], X2[np.argmin(Y)])\n",
        "print('Best objective    : ', min(Y))\n",
        "\n",
        "X_optimum = [1,1] #Known from theory\n",
        "print(\"Known Optimal decision variables:\",X_optimum)\n",
        "print(\"Known Optimal objective =\",Rosenbrock(X_optimum[0], X_optimum[1]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Monte Carlo Simulation Optimisation\n",
            "\n",
            "Best decision variable :  1.0525078343162164 1.1155283544060355\n",
            "Best objective    :  0.00877202613426496\n",
            "Known Optimal decision variables: [1, 1]\n",
            "Known Optimal objective = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnTVEuMvRZEf"
      },
      "source": [
        "'Optimise' above model for different values of N.  Observe how just randomly searching the soultion space yields pretty good results!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42bS-uuXQiTP"
      },
      "source": [
        "##To Do\n",
        "\n",
        "You can find some single objective unconstrained test functions at [Wiki page](https://en.wikipedia.org/wiki/Test_functions_for_optimization)\n",
        "\n",
        "1. Through simulation, estimate the best solution of any one of the function: Beale or Goldstein-Price or Booth (need to minimize)\n",
        "\n",
        "2. 'Minimize' either Himmelblau's function OR Cross-in-Tray function. These functions have 4 alternate solutions.  Do 20 sets of 'simulation-optimisation' runs, with N ~= 200000. Compute the number of times we are close to a particular known solution."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1: Estimation of solution of Beale-function:"
      ],
      "metadata": {
        "id": "vDuOoCjaL7Mb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq3-TrrOSxcj"
      },
      "source": [
        "def beale_function(x,y):\n",
        "  return (1.5-x+x*y)**2+(2.25-x+x*y**2)**2+(2.625-x+x*y**3)**2"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 10000 ## number of random points\n",
        "D = 2 ##Dimension \n",
        "lb = -4 ## lower bound\n",
        "ub = 4  ## upper bound\n",
        "\n",
        "X1=[]\n",
        "X2=[]\n",
        "Y=[]\n",
        "\n",
        "#randomly generate N points. We are using Numpy's random package here.\n",
        "X1 = np.random.uniform(lb, ub, N)\n",
        "X2 = np.random.uniform(lb, ub, N)\n",
        "\n",
        "#Evaluate the function\n",
        "for i in range(N):\n",
        "    Y.append(beale_function(X1[i], X2[i]))\n",
        "    \n",
        "#display Results\n",
        "print('\\n Monte Carlo Simulation Optimisation\\n')\n",
        "print( 'Best decision variable : ', X1[np.argmin(Y)], X2[np.argmin(Y)])\n",
        "print('Best objective    : ', min(Y))\n",
        "\n",
        "X_optimum = [1,1] #Known from theory\n",
        "print(\"Known Optimal decision variables:\",X_optimum)\n",
        "print(\"Known Optimal objective =\",Rosenbrock(X_optimum[0], X_optimum[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5UJFlxGC1RB",
        "outputId": "db0a1044-db14-4113-d619-bf7330d081a2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Monte Carlo Simulation Optimisation\n",
            "\n",
            "Best decision variable :  3.0261314668856656 0.4969567774201611\n",
            "Best objective    :  0.002208318585395428\n",
            "Known Optimal decision variables: [1, 1]\n",
            "Known Optimal objective = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 2:\n",
        "Estimation of Himmelblau function:"
      ],
      "metadata": {
        "id": "iGJFXLz-MSD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Himmelblau_function(x,y):\n",
        "  return (x**2+y-11)**2+(x+y**2-7)**2\n",
        "  "
      ],
      "metadata": {
        "id": "EcOoJHcYDbYL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 200000 ## number of random points\n",
        "D = 2 ##Dimension \n",
        "lb = -5 ## lower bound\n",
        "ub = 5  ## upper bound\n",
        "\n",
        "X1=[]\n",
        "X2=[]\n",
        "num=[]\n",
        "value=[]\n",
        "for i in range(20):\n",
        "  Y=[]\n",
        "  X1 = np.random.uniform(lb, ub, N)\n",
        "  X2 = np.random.uniform(lb, ub, N)\n",
        "  for i in range(N):\n",
        "    Y.append(Himmelblau_function(X1[i], X2[i]))\n",
        "  if min(Y)>-0.1 and min(Y)<0.1:\n",
        "    if X1[np.argmin(Y)]>2.98 and X1[np.argmin(Y)]<3.03 and X2[np.argmin(Y)]>1.98 and X2[np.argmin(Y)]<2.03:\n",
        "      num.append(1)\n",
        "    elif X1[np.argmin(Y)]>-2.82 and X1[np.argmin(Y)]<-2.78 and X2[np.argmin(Y)]>3.11 and X2[np.argmin(Y)]<3.15:\n",
        "      num.append(2)\n",
        "    elif X1[np.argmin(Y)]>-3.79 and X1[np.argmin(Y)]<-3.75 and X2[np.argmin(Y)]>-3.30 and X2[np.argmin(Y)]<-3.26:\n",
        "      num.append(3)\n",
        "    elif X1[np.argmin(Y)]>3.56 and X1[np.argmin(Y)]<3.60 and X2[np.argmin(Y)]>-1.86 and X2[np.argmin(Y)]<-1.82: \n",
        "      num.append(4) \n",
        "    else:\n",
        "      num.append(0)  \n",
        "    value.append((X1[np.argmin(Y)], X2[np.argmin(Y)]))      \n",
        "  else:\n",
        "    num.append(0)\n",
        "  value.append((X1[np.argmin(Y)], X2[np.argmin(Y)]))   \n",
        "count=len(num)-num.count(0)\n",
        "print('Best decision variable',value)\n",
        "print('solution status:',num)\n",
        "print('the number of times we are close to a particular known solution:',count)\n",
        "#Known from theory\n",
        "X_optimum_1 = [3,2] \n",
        "X_optimum_2 = [-2.805118,3.131312]\n",
        "X_optimum_3 = [-3.779310,-3.283186]\n",
        "X_optimum_4 = [3.584428,-1.848126]\n",
        "print(\"Known Optimal decision variables:\",X_optimum_1,X_optimum_2,X_optimum_3,X_optimum_4)\n",
        "print(\"Known Optimal objective =\",Himmelblau_function(X_optimum_1[0], X_optimum_1[1]))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fLSXqIMDsq4",
        "outputId": "b451d4c5-d648-44d1-892b-caf0765abd92"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best decision variable [(2.997239494478368, 2.008440610964376), (2.997239494478368, 2.008440610964376), (2.9971642731183543, 1.9977490217057632), (2.9971642731183543, 1.9977490217057632), (2.9949506558291636, 2.001868086499625), (2.9949506558291636, 2.001868086499625), (-3.7770690159328013, -3.2840834255460303), (-3.7770690159328013, -3.2840834255460303), (2.995714318195172, 2.0111713988395064), (2.995714318195172, 2.0111713988395064), (3.5904502828121636, -1.845839804134898), (3.5904502828121636, -1.845839804134898), (3.583734990930303, -1.8410163041927685), (3.583734990930303, -1.8410163041927685), (-2.7994228474803706, 3.1345081344498755), (-2.7994228474803706, 3.1345081344498755), (3.5834847824890996, -1.8377805096376552), (3.5834847824890996, -1.8377805096376552), (-3.778547110485062, -3.2837340781714075), (-3.778547110485062, -3.2837340781714075), (3.5818856145621307, -1.8514346128995394), (3.5818856145621307, -1.8514346128995394), (-2.816698468034986, 3.1290631306655605), (-2.816698468034986, 3.1290631306655605), (2.9940892192124737, 2.001365012285282), (2.9940892192124737, 2.001365012285282), (3.5822663723353756, -1.8473510762204395), (3.5822663723353756, -1.8473510762204395), (3.583763832234494, -1.8251402168171058), (3.583763832234494, -1.8251402168171058), (-2.8069010109479353, 3.134021481973912), (-2.8069010109479353, 3.134021481973912), (3.004140010339322, 1.9988625961217599), (3.004140010339322, 1.9988625961217599), (-3.7797109979920682, -3.2930154677576216), (-3.7797109979920682, -3.2930154677576216), (3.583639945006329, -1.854547247745597), (3.583639945006329, -1.854547247745597), (2.9928584311405384, 2.0088626533873573), (2.9928584311405384, 2.0088626533873573)]\n",
            "solution status: [1, 1, 1, 3, 1, 4, 4, 2, 4, 3, 4, 2, 1, 4, 4, 2, 1, 3, 4, 1]\n",
            "the number of times we are close to a particular known solution: 20\n",
            "Known Optimal decision variables: [3, 2] [-2.805118, 3.131312] [-3.77931, -3.283186] [3.584428, -1.848126]\n",
            "Known Optimal objective = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Optional To Do"
      ],
      "metadata": {
        "id": "egDzQ619EZWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider flight IEX 306 that flies daily from Mumbai to Chennai. Flight has 100 seats.  Price of a ticket is on an average Rs. 6000.  There is 10% chance that a sold seat will remain vacant (i.e. passenger doesn’t show up). Airline refunds 50% of the price of ticket to that passenger for such last minute cancellations.  \n",
        "Daily demand for seats is Poisson distributed with mean 120.   \n",
        "Now, the airline can decide to sell $x$ tickets, where $x4 can be more or less than the capacity of plane.  \n",
        "If the airline overbooks, then it pays an average of Rs.10000 for any passenger who is ‘bumped’ (i.e. denied seat in plane). \n",
        "\n",
        "What is the value of $x$ (the number of tickets to sell) that maximizes the expected profit? (Hint: You can run the model for different values of $x$ from say 90 to 150 and choose the $x$ which gives the maximum profit)"
      ],
      "metadata": {
        "id": "XhNR0jGoEcOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N=100\n"
      ],
      "metadata": {
        "id": "S8W_g7LBEbcp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}